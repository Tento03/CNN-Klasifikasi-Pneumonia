{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y9IlLedpQRm",
        "outputId": "90402974-f6ad-4690-8268-5feecef8731b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT LIBRARY**"
      ],
      "metadata": {
        "id": "_DbWtrtruEK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input"
      ],
      "metadata": {
        "id": "wSJGEvjQpRjQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUGMENTASI WITH IMAGEDATAGENERATOR**"
      ],
      "metadata": {
        "id": "4L3ztqTGuI59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=ImageDataGenerator(\n",
        "    rescale=1.255,\n",
        "    width_shift_range=0.2,\n",
        "    rotation_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "Gbn7OP5mp0nl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=train_generator.flow_from_directory(\n",
        "    '/content/drive/MyDrive/covid_xray/xray/train/',\n",
        "    target_size=(48,48),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hAfnEaZqHzE",
        "outputId": "17da048c-b9ae-49e7-c6be-380840a044ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 148 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator=ImageDataGenerator(\n",
        "    rescale=1.255\n",
        ")"
      ],
      "metadata": {
        "id": "qg_Q_ERSqvUu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set=test_generator.flow_from_directory(\n",
        "    '/content/drive/MyDrive/covid_xray/xray/test/',\n",
        "    target_size=(48,48),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEQbXtiArUIq",
        "outputId": "f85d4c5d-ba39-4197-b717-5c646329ca49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN MODEL BUILDING**"
      ],
      "metadata": {
        "id": "2rDRzwVzuN6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),input_shape=(48,48,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HNelBNhrhLZ",
        "outputId": "6680d108-8472-40ce-bb55-1c2caf98c15a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UVYlrVxDr-kx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_set,validation_data=(test_set),epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL9vAJgmsoAs",
        "outputId": "f72f4326-618d-4048-b454-4a10aa60682c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.4529 - loss: 80.4183 - val_accuracy: 0.5000 - val_loss: 38.4120\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 769ms/step - accuracy: 0.4757 - loss: 44.2018 - val_accuracy: 0.8000 - val_loss: 1.0752\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 332ms/step - accuracy: 0.5396 - loss: 7.3434 - val_accuracy: 0.5750 - val_loss: 4.1053\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 331ms/step - accuracy: 0.5878 - loss: 3.8868 - val_accuracy: 0.6250 - val_loss: 0.9661\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 764ms/step - accuracy: 0.5501 - loss: 1.5837 - val_accuracy: 0.8500 - val_loss: 0.3350\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.6520 - loss: 0.9712 - val_accuracy: 0.8500 - val_loss: 0.2478\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 480ms/step - accuracy: 0.7177 - loss: 0.9353 - val_accuracy: 0.8500 - val_loss: 0.2587\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 334ms/step - accuracy: 0.7536 - loss: 0.6610 - val_accuracy: 0.7500 - val_loss: 0.5148\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 533ms/step - accuracy: 0.7371 - loss: 0.6076 - val_accuracy: 0.9250 - val_loss: 0.2803\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.7689 - loss: 0.4223 - val_accuracy: 0.9250 - val_loss: 0.3751\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 321ms/step - accuracy: 0.7447 - loss: 0.5617 - val_accuracy: 0.8500 - val_loss: 0.2932\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 397ms/step - accuracy: 0.8106 - loss: 0.4176 - val_accuracy: 0.9250 - val_loss: 0.1775\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 331ms/step - accuracy: 0.8458 - loss: 0.3954 - val_accuracy: 0.9000 - val_loss: 0.2588\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 782ms/step - accuracy: 0.7760 - loss: 0.5223 - val_accuracy: 0.9500 - val_loss: 0.1630\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 401ms/step - accuracy: 0.6622 - loss: 0.6646 - val_accuracy: 0.8000 - val_loss: 0.3249\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 335ms/step - accuracy: 0.7564 - loss: 0.4500 - val_accuracy: 0.9000 - val_loss: 0.2340\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 351ms/step - accuracy: 0.8113 - loss: 0.3801 - val_accuracy: 0.9500 - val_loss: 0.2044\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 325ms/step - accuracy: 0.7179 - loss: 0.5845 - val_accuracy: 0.9500 - val_loss: 0.1643\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 476ms/step - accuracy: 0.8126 - loss: 0.4076 - val_accuracy: 0.9750 - val_loss: 0.1402\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 341ms/step - accuracy: 0.8166 - loss: 0.4000 - val_accuracy: 1.0000 - val_loss: 0.1134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F_ZR83JouRQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE THE MODEL**"
      ],
      "metadata": {
        "id": "iHDn8oJSuRRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cnn.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M49GkDCt5AN",
        "outputId": "eb91d99b-2ed7-4f2e-f1fa-08e85e4729e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDIKSI**"
      ],
      "metadata": {
        "id": "jc3IW5zRuUcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from tensorflow.keras.models import load_model  # Tambahkan import untuk load_model\n",
        "\n",
        "\n",
        "# Memuat model yang sudah dilatih\n",
        "model_path = 'cnn.h5'  # Sesuaikan dengan path model Anda\n",
        "model = load_model(model_path)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f'File {filename} successfully uploaded.')\n",
        "\n",
        "# Ambil nama file gambar yang diunggah (mungkin perlu disesuaikan sesuai dengan nama file yang Anda unggah)\n",
        "uploaded_image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load dan praproses gambar\n",
        "img = image.load_img(uploaded_image_path, target_size=(48, 48))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array /= 255.0  # Normalisasi nilai piksel\n",
        "\n",
        "# Tampilkan gambar yang diuji\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Ubah gambar menjadi bentuk yang dapat digunakan oleh model\n",
        "input_image = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Lakukan prediksi\n",
        "predictions = model.predict(input_image)\n",
        "\n",
        "# Dapatkan label kelas prediksi\n",
        "predicted_class = np.argmax(predictions)\n",
        "\n",
        "# Misalnya, jika Anda memiliki file label seperti label_names\n",
        "label_names = ['NORMAL','PNEUMONIA']\n",
        "predicted_label = label_names[predicted_class]\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "print(f'Predicted Class: {predicted_label}')"
      ],
      "metadata": {
        "id": "1BB-zm1YswOQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}